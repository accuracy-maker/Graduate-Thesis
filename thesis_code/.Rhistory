data(rainfall)
str(rainfall)
library(SpatialExtremes)
rainfall = data(rainfall)
str(rainfall)
library(SpatialExtremes)
data(rainfall)
View(rain)
# load libraries
library(SpatialExtremes)
library(ggplot2)
install.packages(ggplot2)
install.packages("ggplot2")
install.packages("dplyr")
install.packages("maps")
# load libraries
library(SpatialExtremes)
library(ggplot2)
library(dplyr)
library(maps)
data(rainfall)
print("Dataset structure:")
str(rainfall)
data(rainfall)
print("Dataset structure:")
str(rain)
print("Available datasets in SpatialExtremes:")
data(package = "SpatialExtremes")
print("Dataset structure:")
str(rain)
print("\nDataset summary:")
summary(rain)
print("\nFirst few rows:")
head(rain)
# Check for missing values
print("\nMissing values:")
colSums(is.na(rain))
# Visualize the spatial distribution of stations
plot(rain$lon, rain$lat,
main = "Spatial Distribution of Rainfall Stations",
xlab = "Longitude", ylab = "Latitude",
pch = 19, col = "blue", cex = 0.8)
View(coord)
plot(coord$lon, coord$lat,
main = "Spatial Distribution of Rainfall Stations",
xlab = "Longitude", ylab = "Latitude",
pch = 19, col = "blue", cex = 1.2)
View(coord)
View(coord)
str(coord)
plot(coord[, "lon"], coord[, "lat"],
main = "Spatial Distribution of Rainfall Stations",
xlab = "Longitude", ylab = "Latitude",
pch = 19, col = "blue", cex = 1.2)
View(rain)
fit <- fitmaxstab(data = rain, coord = coord[, 1:2], cov.mod = "brown")
summary(fit)
plot(fit, which = "variogram")
set.seed(123)
# Simulate 100 samples of 3D unit Pareto margins
n <- 100
X <- matrix(rexp(n * 3, rate = 1), ncol = 3)  # exponential(1) has Pareto(1) tail
# Load the library
library(scatterplot3d)
install.packages("scatterplot3d")
# Load the library
library(scatterplot3d)
# Plot the 3D Pareto-like points
scatterplot3d(X[,1], X[,2], X[,3],
pch = 16, color = "blue",
xlab = "X1", ylab = "X2", zlab = "X3",
main = "3D Simulated Extreme Data")
r_L1 <- function(x) rowSums(x)
u <- 5  # threshold
Z <- X[r_L1(X) > u, ]  # this is the r-Pareto sample with L1 functional
# Load the library
library(scatterplot3d)
# Plot the 3D Pareto-like points
s3d <- scatterplot3d(X, color = "blue", pch = 16,
xlab = "X1", ylab = "X2", zlab = "X3",
main = "L1-thresholded Extreme Points")
s3d$points3d(Z, col = "red", pch = 16)
s3d <- scatterplot3d(X, color = "blue", pch = 16,
xlab = "X1", ylab = "X2", zlab = "X3",
main = "L1-thresholded Extreme Points")
s3d$points3d(Z, col = "red", pch = 16)
Z_normalized <- Z / r_L1(Z)
scatterplot3d(Z_normalized, color = "blue", pch = 16,
main = "Angular component of L1 r-Pareto process")
# Plot the normalized points
s3d <- scatterplot3d(Z_normalized, color = "blue", pch = 16,
xlab = "X1", ylab = "X2", zlab = "X3",
main = "L1 r-Pareto: Angular Component on Plane")
# Add the plane x + y + z = 1
# That is: x3 = 1 - x1 - x2 ⇒ intercept = 1, coefficients = -1, -1
s3d$plane3d(a = -1, b = -1, c = 1, draw_polygon = TRUE,
polygon_args = list(col = rgb(1, 0, 0, 0.3)))
# Plot the normalized points
s3d <- scatterplot3d(Z_normalized, color = "blue", pch = 16,
xlab = "X1", ylab = "X2", zlab = "X3",
main = "L1 r-Pareto: Angular Component on Plane")
# Add the plane x + y + z = 1
# That is: x3 = 1 - x1 - x2 ⇒ intercept = 1, coefficients = -1, -1
s3d$plane3d(a = -1, b = -1, intercept = 1,
draw_polygon = TRUE,
polygon_args = list(col = rgb(1, 0, 0, 0.3)))
# Plot the normalized points
s3d <- scatterplot3d(Z_normalized, color = "blue", pch = 16,
xlab = "X1", ylab = "X2", zlab = "X3",
main = "L1 r-Pareto: Angular Component on Plane")
# Add the plane x + y + z = 1
# That is: x3 = 1 - x1 - x2 ⇒ intercept = 1, coefficients = -1, -1
s3d$plane3d(a = -1, b = -1, Intercept = 1,
draw_polygon = TRUE,
polygon_args = list(col = rgb(1, 0, 0, 0.3)))
s3d <- scatterplot3d(Z_normalized, color = "blue", pch = 16,
xlab = "X1", ylab = "X2", zlab = "X3",
main = "L1 r-Pareto Sphere with Plane x+y+z=1")
# Step 3: draw the plane x + y + z = 1 (z = 1 - x - y)
# We'll create a triangle (x, y) such that x + y <= 1
x_vals <- seq(0, 1, length.out = 20)
y_vals <- seq(0, 1, length.out = 20)
# Get only points where x + y <= 1 (to stay within valid region)
grid <- expand.grid(x = x_vals, y = y_vals)
grid <- subset(grid, x + y <= 1)
grid$z <- 1 - grid$x - grid$y
# Convert to 2D projection using s3d$xyz.convert
proj <- s3d$xyz.convert(grid$x, grid$y, grid$z)
# Draw the plane as a transparent polygon mesh
polygon(proj$x, proj$y, col = rgb(1, 0, 0, 0.2), border = NA)
install.packages("stats4")
set.seed(123)
n <- 1000
X <- matrix(rexp(n * 3), ncol = 3)
r_L1 <- function(x) rowSums(x)
u <- 6
X_u <- X[r_L1(X) > u, ]
nA <- nrow(X_u)
# Load required libraries
library(ggplot2)
# Parameters
set.seed(123)
n <- 100000  # number of samples
d <- 3       # dimension
u <- 6       # threshold
# 1. Simulate Exponential(1) samples (Pareto tails)
X <- matrix(rexp(n * d, rate = 1), ncol = d)
L1_norm <- rowSums(X)
# 2. Monte Carlo approximation of kappa_D(A)
p_mc <- mean(L1_norm > u)
# 3. Analytical approximation using Gamma CDF
p_analytic <- 1 - pgamma(u, shape = d, rate = 1)
# 4. Print both results
cat("Monte Carlo estimate of kappa_D(A):", round(p_mc, 5), "\n")
cat("Analytic estimate of kappa_D(A)   :", round(p_analytic, 5), "\n")
# 5. Create data frame for ggplot
df <- data.frame(L1 = L1_norm)
# 6. Plot histogram with Gamma PDF and tail
ggplot(df, aes(x = L1)) +
geom_histogram(aes(y = ..density..), bins = 100, fill = "skyblue", alpha = 0.5) +
stat_function(fun = function(x) dgamma(x, shape = d, rate = 1),
color = "red", size = 1.1, linetype = "solid") +
geom_vline(xintercept = u, color = "black", linetype = "dashed", size = 1) +
annotate("text", x = u + 1, y = 0.05, label = paste("Threshold u =", u), color = "black") +
labs(
title = "L1 Norm Distribution: Monte Carlo vs Analytic Gamma Approximation",
subtitle = paste0("kappa_D(A): Monte Carlo = ", round(p_mc, 5),
" | Analytic = ", round(p_analytic, 5)),
x = "L1 Norm ||X||₁", y = "Density"
) +
theme_minimal()
# Load required libraries
# Load required libraries
library(ggplot2)
# Parameters
set.seed(123)
n <- 100000  # number of samples
d <- 3       # dimension
u <- 6       # threshold
# 1. Simulate Exponential(1) samples (Pareto tails)
X <- matrix(rexp(n * d, rate = 1), ncol = d)
L1_norm <- rowSums(X)
# 2. Monte Carlo approximation of kappa_D(A)
p_mc <- mean(L1_norm > u)
# 3. Maximum Likelihood Estimation (MLE) of lambda for exponential margins
lambda_mle <- 1 / mean(X)  # since mean of Exp(lambda) = 1 / lambda
# 4. Analytical approximation using estimated lambda
p_analytic_mle <- 1 - pgamma(u, shape = d, rate = lambda_mle)
# 5. Analytical approximation using true lambda = 1
p_analytic_true <- 1 - pgamma(u, shape = d, rate = 1)
# 6. Print all results
cat("Monte Carlo estimate      : ", round(p_mc, 5), "\n")
cat("Analytic (true λ = 1)     : ", round(p_analytic_true, 5), "\n")
cat("Analytic (MLE λ =", round(lambda_mle, 5), "):", round(p_analytic_mle, 5), "\n")
# 7. Create data frame for ggplot
df <- data.frame(L1 = L1_norm)
# 8. Plot histogram with Gamma PDFs (true vs MLE)
ggplot(df, aes(x = L1)) +
geom_histogram(aes(y = ..density..), bins = 100, fill = "skyblue", alpha = 0.5) +
stat_function(fun = function(x) dgamma(x, shape = d, rate = 1),
color = "red", size = 1.2, linetype = "solid") +
stat_function(fun = function(x) dgamma(x, shape = d, rate = lambda_mle),
color = "darkgreen", size = 1.2, linetype = "dashed") +
geom_vline(xintercept = u, color = "black", linetype = "dashed", size = 1) +
annotate("text", x = u + 1, y = 0.05, label = paste("Threshold u =", u), color = "black") +
labs(
title = "L1 Norm ||X||₁ Distribution with MLE Fitting",
subtitle = paste0(
"Monte Carlo = ", round(p_mc, 5),
" | Analytic (true λ) = ", round(p_analytic_true, 5),
" | Analytic (MLE λ) = ", round(p_analytic_mle, 5)
),
x = "L1 Norm ||X||₁", y = "Density"
) +
theme_minimal()
library(SpatialExtremes)
data(rain)
library(SpatialExtremes)
data(rainfall)
rain_rank <- apply(rain, 2, rank)
rain_pareto <- 1 / (1 - rain_rank / (nrow(rain) + 1))
View(rain_pareto)
View(rain)
r_L1 <- function(x) rowSums(x)
u <- quantile(r_L1(rain_pareto), 0.95)  # top 5% threshold
idx <- which(r_L1(rain_pareto) > u)
Z <- rain_pareto[idx, ]
View(Z)
View(Z)
u <- quantile(r_L1(rain_pareto), 0.9)  # top 5% threshold
idx <- which(r_L1(rain_pareto) > u)
Z <- rain_pareto[idx, ]
u <- quantile(r_L1(rain_pareto), 0.95)  # top 5% threshold
idx <- which(r_L1(rain_pareto) > u)
Z <- rain_pareto[idx, ]
Z_ang <- Z / r_L1(Z)
# Step 5: Fit Brown–Resnick model using spectral likelihood
fit_rpareto <- fitextremal(
data = Z_ang,
coord = coord[, 1:2],
cov.mod = "brown",
method = "spectral",  # pseudo-likelihood approximation
loc.form = ~1,
control = list(trace = 1)
)
# Step 5: Fit Brown–Resnick model using spectral likelihood
fit1 <- fitmaxstab(data = Z_ang, coord = coord, cov.mod = "brown")
# Step 6: Summarize results
summary(fit1)
plot(fit1)
# Step 5: Fit Brown–Resnick model using spectral likelihood
fit1 <- fitmaxstab(data = Z_ang, coord = coord, cov.mod = "brown")
# Step 6: Summarize results
summary(fit1)
library(SpatialExtremes)   # rainfall data set
library(mvPot)             # exact r-Pareto simulator
install.packages("mvPot")
library(SpatialExtremes)   # rainfall data set
library(mvPot)             # exact r-Pareto simulator
library(fields)            # distances
library(ks)                # kernel density on the simplex
install.packages("ks"])
install.packages("ks")
library(SpatialExtremes)   # rainfall data set
library(mvPot)             # exact r-Pareto simulator
library(fields)            # distances
library(ks)                # kernel density on the simplex
set.seed(42)
data(rainfall)
Y      <- rainfall$rain
data(rainfall)
Y      <- rain
rank_Y       <- apply(Y, 2, rank, ties.method = "average")
Y_pareto     <- 1 / (1 - rank_Y / (nrow(Y) + 1))
r_L1   <- function(x) rowSums(x)      # L1 risk functional
u      <- quantile(r_L1(Y_pareto), .95)      # 95-th radial quantile
exc_id <- which(r_L1(Y_pareto) > u)
Z_obs  <- Y_pareto[exc_id, ]
Z_ang  <- Z_obs / r_L1(Z_obs)          # angular component  (∑ Z = 1)
r_L1   <- function(x) rowSums(x)      # L1 risk functional
u      <- quantile(r_L1(Y_pareto), .95)      # 95-th radial quantile
exc_id <- which(r_L1(Y_pareto) > u)
Z_obs  <- Y_pareto[exc_id, ]
Z_ang  <- Z_obs / r_L1(Z_obs)          # angular component  (∑ Z = 1)
cat(sprintf("Observed r-Pareto sample size  :  %i\n", nrow(Z_ang)))
sim_rPareto <- function(n, coords, rho, alpha)
{
varioFun <- function(h) (sqrt(sum(h^2)) / rho)^alpha
mvPot::simulPareto(n, loc = coords, vario = varioFun,
riskF = "sum", normalize = FALSE)
}
d_med <- median(fields::rdist(coord))
par0  <- c(log(d_med), qlogis(.5))  #  (log ρ, logit α)
opt <- optim(par0, fn = loglik_MC, Z_obs = Z_ang, coords = coord,
method = "Nelder-Mead", control = list(fnscale = -1, maxit = 60))
loglik_MC <- function(par, Z_obs, coords, n_MC = 5e4, h_bw = .015)
{
rho   <- exp(par[1])           # enforce positivity
alpha <- plogis(par[2], 0, 1) * 2   # map (-∞,∞) → (0,2)
# ---------- Monte-Carlo spectral simulation ----------
W <- sim_rPareto(n_MC, coords, rho, alpha)         # n_MC × D
R <- r_L1(W)
keep <- R > 1
Z_mc <- W[keep, ] / R[keep]
# acceptance-rate estimate   κ(𝒜_r;θ)  (needed only for info)
kappa_Ar_hat <- mean(keep)
# ---------- kernel density on the simplex -------------
# log-ratio coordinates remove the sum-to-one constraint (D-1 dims)
clr <- function(z) { log(z) - mean(log(z)) }
Z_clr_mc  <- t(apply(Z_mc, 1, clr))
Z_clr_obs <- t(apply(Z_obs, 1, clr))
kd <- ks::kde(x = Z_clr_mc, H = diag(h_bw, ncol(Z_clr_mc))) # Gaussian KDE
log_kappa_hat <- ks::predict(kd, x = Z_clr_obs, log = TRUE)
# Monte-Carlo log-likelihood (normalising constant cancels out)
sum(log_kappa_hat)
}
d_med <- median(fields::rdist(coord))
par0  <- c(log(d_med), qlogis(.5))  #  (log ρ, logit α)
opt <- optim(par0, fn = loglik_MC, Z_obs = Z_ang, coords = coord,
method = "Nelder-Mead", control = list(fnscale = -1, maxit = 60))
loglik_MC <- function(par, Z_obs, coords, n_MC = 5e4, h_bw = .015)
{
rho   <- exp(par[1])                    # range  > 0
alpha <- plogis(par[2]) * 2             # smooth ∈ (0,2]
## ---- exact Pareto simulation (accept–reject inside) --------------------
vfun  <- function(h) vario_fun(h, rho, alpha)
Wlist <- simulPareto(n_MC, loc = coords, vario = vfun)
acc   <- attr(Wlist, "accept.rate")     # κ(𝒜_r;θ) — for diagnostics only
Wmat  <- do.call(rbind, Wlist)          # list -> matrix
Z_mc  <- Wmat / rowSums(Wmat)           # angular component
## ---- kernel density in centred-log-ratio coords ------------------------
clr <- function(z) log(z) - mean(log(z))
Zclr_mc  <- t(apply(Z_mc , 1, clr))
Zclr_obs <- t(apply(Z_obs, 1, clr))
kd <- ks::kde(x = Zclr_mc, H = diag(h_bw, ncol(Zclr_mc)))
ll <- sum(ks::predict(kd, x = Zclr_obs, log = TRUE))   # MC log-likelihood
attr(ll, "acc.rate") <- acc
ll
}
d_med <- median(fields::rdist(coord))
par0  <- c(log(d_med), qlogis(0.75))   # crude start
opt <- optim(par0, fn = loglik_MC, Z_obs = Z_ang, coords = coord,
method = "Nelder-Mead", control = list(fnscale = -1, maxit = 60))
sim_rPareto <- function(n_total, coords, rho, alpha)
{
out <- sim_rPareto_BR(n_total, coords, rho, alpha)
attr(out$Z, "accept.rate") <- out$accept.rate
out$Z
}
loglik_MC <- function(par, Z_obs, coords, n_MC = 5e4, h_bw = .015)
{
rho   <- exp(par[1])
alpha <- plogis(par[2]) * 2
Z_mc  <- sim_rPareto(n_MC, coords, rho, alpha)          # <-- new call
acc   <- attr(Z_mc, "accept.rate")                      # acceptance prob
# --- kernel density on centred-log-ratio transform ----------------------
clr <- function(z) log(z) - mean(log(z))
Z_clr_mc  <- t(apply(Z_mc , 1, clr))
Z_clr_obs <- t(apply(Z_obs, 1, clr))
kd <- ks::kde(x = Z_clr_mc, H = diag(h_bw, ncol(Z_clr_mc)))
ll <- sum(ks::predict(kd, x = Z_clr_obs, log = TRUE))
attr(ll, "acc.rate") <- acc
ll
}
d_med <- median(fields::rdist(coord))
par0  <- c(log(d_med), qlogis(0.75))   # crude start
opt <- optim(par0, fn = loglik_MC,
Z_obs = Z_ang, coords = coord,
method = "Nelder-Mead",
control = list(fnscale = -1, maxit = 60))
library(SpatialExtremes)   # rainfall data set
library(mvPot)             # exact r-Pareto simulator
library(fields)            # distances
library(ks)                # kernel density on the simplex
set.seed(42)
data(rainfall)
Y      <- rain
coords <- coord[1:2]
data(rainfall)
Y      <- rain
coords <- coord[1,2]
data(rainfall)
Y      <- rain
coords <- coord[, 1:2]
r_L1     <- function(x) rowSums(x)
u        <- quantile(r_L1(Y_par), 0.95)            # 95-th radial threshold
rank_Y   <- apply(Y, 2, rank, ties.method = "average")
Y_par    <- 1 / (1 - rank_Y / (nrow(Y) + 1))      # unit-Pareto
r_L1     <- function(x) rowSums(x)
u        <- quantile(r_L1(Y_par), 0.95)            # 95-th radial threshold
idx_exc  <- which(r_L1(Y_par) > u)
Z_obs    <- Y_par[idx_exc, ]
Z_ang    <- Z_obs / r_L1(Z_obs)                    # angular part (∑ Z = 1)
cat(sprintf("\nObserved r-Pareto angles above 95-th percentile : %d\n",
nrow(Z_ang)))
sim_br_spectral <- function(n, coords, rho, alpha)
{
gamma_h  <- function(h) (h / rho)^alpha
Dmat     <- as.matrix(dist(coords))
gamma_ij <- gamma_h(Dmat)
gamma0   <- gamma_h(sqrt(rowSums(coords^2)))     # γ(‖s_i‖)
Sigma    <- 0.5 * outer(gamma0, gamma0, "+") - 0.5 * gamma_ij
mu       <- -0.5 * diag(Sigma)
Y        <- mvtnorm::rmvnorm(n, mean = mu, sigma = Sigma)
exp(Y)                                         #  n × d  matrix
}
sim_rPareto_BR <- function(n_total, coords, rho, alpha)
{
W        <- sim_br_spectral(n_total, coords, rho, alpha)
R        <- rowSums(W)
keep     <- R > 1
Z_keep   <- W[keep, ] / R[keep]                # angular component
structure(Z_keep,
accept.rate = mean(keep),
n.accept    = sum(keep))
}
loglik_MC <- function(par, Z_obs, coords,
n_MC = 5e4, h_bw = 0.015)       # ← tune these two
{
rho   <- exp(par[1])              # ensure ρ > 0
alpha <- plogis(par[2]) * 2       # map (-∞,∞) → (0,2]
Z_mc  <- sim_rPareto_BR(n_MC, coords, rho, alpha)
acc   <- attr(Z_mc, "accept.rate")                # diagnostics only
## centred-log-ratio transform  (maps simplex → ℝ^{d-1})
clr <- function(z) log(z) - mean(log(z))
Z_clr_mc  <- t(apply(Z_mc , 1, clr))
Z_clr_obs <- t(apply(Z_obs, 1, clr))
kd  <- ks::kde(x = Z_clr_mc, H = diag(h_bw, ncol(Z_clr_mc)))
ll  <- sum(ks::predict(kd, x = Z_clr_obs, log = TRUE))   # MC log-lik
attr(ll, "acc.rate") <- acc
ll
}
rho0  <- median(fields::rdist(coords))
par0  <- c(log(rho0), qlogis(0.5))            # (log ρ₀, logit α₀)
opt <- optim(par0,
fn       = loglik_MC,
Z_obs    = Z_ang,
coords   = coords,
method   = "Nelder-Mead",
control  = list(fnscale = -1, maxit = 80, reltol = 1e-4))
loglik_MC <- function(par, Z_obs, coords,
n_MC = 5e4, h_bw = 0.015)       # ← tune these two
{
rho   <- exp(par[1])              # ensure ρ > 0
alpha <- plogis(par[2]) * 2       # map (-∞,∞) → (0,2]
Z_mc  <- sim_rPareto_BR(n_MC, coords, rho, alpha)
acc   <- attr(Z_mc, "accept.rate")                # diagnostics only
## centred-log-ratio transform  (maps simplex → ℝ^{d-1})
clr <- function(z) log(z) - mean(log(z))
Z_clr_mc  <- t(apply(Z_mc , 1, clr))
Z_clr_obs <- t(apply(Z_obs, 1, clr))
kd  <- ks::kde(x = Z_clr_mc, H = diag(h_bw, ncol(Z_clr_mc)), binned=FALSE)
ll  <- sum(ks::predict(kd, x = Z_clr_obs, log = TRUE))   # MC log-lik
attr(ll, "acc.rate") <- acc
ll
}
loglik_MC <- function(par, Z_obs, coords,
n_MC = 1, h_bw = 0.015)       # ← tune these two
{
rho   <- exp(par[1])              # ensure ρ > 0
alpha <- plogis(par[2]) * 2       # map (-∞,∞) → (0,2]
Z_mc  <- sim_rPareto_BR(n_MC, coords, rho, alpha)
acc   <- attr(Z_mc, "accept.rate")                # diagnostics only
## centred-log-ratio transform  (maps simplex → ℝ^{d-1})
clr <- function(z) log(z) - mean(log(z))
Z_clr_mc  <- t(apply(Z_mc , 1, clr))
Z_clr_obs <- t(apply(Z_obs, 1, clr))
kd  <- ks::kde(x = Z_clr_mc, H = diag(h_bw, ncol(Z_clr_mc)), binned=FALSE)
ll  <- sum(ks::predict(kd, x = Z_clr_obs, log = TRUE))   # MC log-lik
attr(ll, "acc.rate") <- acc
ll
}
rho0  <- median(fields::rdist(coords))
par0  <- c(log(rho0), qlogis(0.5))            # (log ρ₀, logit α₀)
opt <- optim(par0,
fn       = loglik_MC,
Z_obs    = Z_ang,
coords   = coords,
method   = "Nelder-Mead",
control  = list(fnscale = -1, maxit = 80, reltol = 1e-4))
loglik_MC <- function(par, Z_obs, coords,
n_MC = 5e4, h_bw = 0.015)
{
rho   <- exp(par[1])
alpha <- plogis(par[2]) * 2
Z_mc  <- sim_rPareto_BR(n_MC, coords, rho, alpha)
acc   <- attr(Z_mc, "accept.rate")
clr <- function(z) log(z) - mean(log(z))
Z_clr_mc  <- t(apply(Z_mc , 1, clr))
Z_clr_obs <- t(apply(Z_obs, 1, clr))
kd <- ks::kde(x = Z_clr_mc,
H = diag(h_bw, ncol(Z_clr_mc)),
binned     = FALSE,
eval.points = Z_clr_obs)
ll  <- sum(kd$estimate)              # Monte-Carlo log-likelihood
attr(ll, "acc.rate") <- acc
ll
}
rho0  <- median(fields::rdist(coords))
par0  <- c(log(rho0), qlogis(0.5))            # (log ρ₀, logit α₀)
opt <- optim(par0,
fn       = loglik_MC,
Z_obs    = Z_ang,
coords   = coords,
method   = "Nelder-Mead",
control  = list(fnscale = -1, maxit = 80, reltol = 1e-4))
rho_hat   <- exp(opt$par[1])
alpha_hat <- plogis(opt$par[2]) * 2
acc_hat   <- attr(opt$value, "acc.rate")
cat(sprintf(
"\n================  Monte-Carlo MLE  =================\n  Range  ρ  : %6.2f km\n  Smooth α : %5.3f\n  MC accept-rate κ(𝒜_r;θ̂) ≈ %.4f\n====================================================\n",
rho_hat, alpha_hat, acc_hat))
